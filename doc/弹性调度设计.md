### 弹性调度设计
因为需要感知集群节点的变化，同时也需要有一个协调同步的机制。引入了zookeeper来实现的弹性调度模块，方案参考了Elastic-Job与Dolphin-Scheduler。以下是设计细节

#### zookeeper数据结构设计
- /live/{nodes}：记录所有存活的节点，里面的信息是address和分片的范围、{nodes}是临时节点；当它发生变化的时候，就会触发 shard 操作。而 /live本身是持久的节点、上面的数据记录着每个节点的负责taskIds范围
- /all/{nodes}：记录所有接入的节点、用作后续拓展备份，永久节点
- /election：永久节点，用于创建leader的前置
- /election/leader：临时节点，leader可以把自己的 address信息写入节点。
- /shard：临时节点，当节点存在时、所有的调度节点会暂停调度工作。shard节点是当 /live 路径下节点数量发生变化，由leader创建，并于shard工作结束后删除。

流程图如下：
![img.png](imgs/shard-1.png)

#### Shard的流程
- 1./live 路径下节点数量发生了变化、leader会创建/shard、而所有的节点都注册了对/shard的watcher、通过这种机制来通知其他的节点、暂停调度
- 2.leader会根据分片策略将最新的分片数据写入/live 节点中，所有节点都是通过感知/live 的node_changed来获取最新的shard计划
- 3.leader将/shard节点删除（为了下一个shard过程能正常启动）
##### 分片策略
目前提供的默认分片策略是：ScopeStrategy、后续可进行拓展选择。这个策略简单来说就是将所有的任务划分成一个个范围，将每个调度节点对应到这些范围，只负责自己范围内的任务。当节点变化，则范围也会跟着扩张或者收缩
- 1.将任务总数除以总节点数，得到平均每个节点的负载
- 2.将节点按照地址排序，排序的好处是可以让节点负责的范围更加稳定
- 3.由于任务数与节点数可能不是整除关系，所以最后一个节点的负责范围就会扩张到任务总数，而不是单纯的按照平均的负载进行。
  
假设总数2300个任务，3个节点的平均负载是 760，那么节点负责的范围依次是1～760，761～1521，1522～2300
#### 容错设计
引入zk且进行leader选举后总是要担心如果发生了 脑裂、以及网络分区/抖动 时系统是怎么容灾的。先让我们来看看其他项目是咋做的
##### Elastic-Job 作业与注册中心无法通信会如何?
为了保证作业的在分布式场景下的一致性，一旦作业与注册中心无法通信，运行中的作业会立刻停止执行，但作业的进程不会退出。 

这样做的目的是为了防止作业重分片时，将与注册中心失去联系的节点执行的分片分配给另外节点，导致同一分片在两个节点中同时执行。 当作业节点恢复与注册中心联系时，将重新参与分片并恢复执行新的分配到的分片。
##### Dolphin-Scheduler 宕机容错
由于” 网络抖动”可能会使得节点短时间内失去和ZooKeeper的心跳，从而发生节点的remove事件。对于这种情况，DS使用最简单的方式，那就是节点一旦和ZooKeeper发生超时连接，则直接将Master或Worker服务停掉。

故障节点上面的任务由其他的节点进行恢复、如果是Master类型的节点则重新遍历 DAG 找到”正在运行”和“提交成功”的任务，对”正在运行”的任务监控其任务实例的状态，对”提交成功”的任务需要判断Task Queue中是否已经存在，如果存在则同样监控任务实例的状态，如果不存在则重新提交任务实例。

参考文档：

https://shardingsphere.apache.org/elasticjob/current/cn/features/elastic/

https://dolphinscheduler.apache.org/zh-cn/docs/2.0.0/user_doc/architecture/design.html